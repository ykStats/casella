[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Casella-Statistical Inference",
    "section": "",
    "text": "Probability Theory\nExpectations\nDistributions\nMultiple Random Variables\nRandom Samples\nData Reduction\nPoint Estimation\nHypothesis Testing\nInterval Estimation\nAsymptotic Evaluations\nANOVA and Regression\nLogistic Regression"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Chap 01: Probability Theory",
    "section": "",
    "text": "Definition 1.1.2 Let A, B be events, subsets of S, then:\nUnion: The union of A and B, written \\(A \\cup B\\) is the set of elements that belong to either A or B or both: \\[ A \\cup B = \\{x: x \\in A \\text{ or } x \\in B\\} \\] Intersection: The intersection of A and B, written \\(A \\cap B\\) is the set of elements that belong to both A and B: \\[ A \\cap B = \\{x: x \\in A \\text{ and } x \\in B\\} \\] Complement: The complement of A, written as \\(A^c\\), is the set of all elements that are not in A: \\[ A^c = \\{x: x \\notin A \\} \\]\n\n\nTheorem 1.1.4 For any three events, A, B and C, defined on a sample space S,\n\\[\\begin{array}{l l}\na. Commutativity    & A \\cup B = B \\cup A,\\\\\n                        & A \\cap B = B \\cap A;\\\\\nb. Associativity    & A \\cup (B \\cup C) = (A \\cup B)\\cup C,\\\\\n                        & $A \\cap (B \\cap C) = (A \\cap B)\\cap C;\\\\\nc. Distributive Laws    & A \\cap (B \\cup C) = (A \\cap B)\\cup (A \\cap C),\\\\\n                        & $A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C);\\\\\nd. DeMorgan's Laws & (A \\cup B)^c = A^c \\cap B^c ,\\\\\n                   & (A \\cap B)^c = A^c \\cup B^c .\n\n\\end{array}\\]\n\n\n\n\nDefinition If \\(A_1, A_2, A_3, \\ldots\\) is a collection of sets, all defined on a sample space \\(S\\), then\n\\[\\begin{align*}\n\\bigcup_{i=1}^\\infty A_i &= \\{x \\in S: x \\in A_i  \\text{ for some }i\\},\\\\\n\\bigcap_{i=1}^\\infty A_i &= \\{x \\in S: x \\in A_i  \\text{ for all }i\\}.\\\\\n\\end{align*}\\]\n\n\n\nDefinition 1.1.5 Two events \\(A\\) and \\(B\\) are disjoint (or mutually exclusive) if \\(A \\cap B = 0\\). The events \\(A_1,A_2,\\ldots\\) are pairwise disjoint (or mutually exclusive) if \\(A_i \\cap A_j = 0 \\text{ for all } i \\ne j\\).\n\n\n\nDefinition 1.1.6 If \\(A_1,A_2,\\ldots\\) are pairwise disjoint and \\(\\bigcup_{i=0}^\\infty A_i = S\\), then the collection \\(A_1, A_2, \\dots\\) forms a partition of S.\n\n\n\n\n\n\nDefinition 1.2.1 A collection of subsets of S is called a sigma algebra (or Borel field ), denoted by \\(\\mathscr{B}\\), if it satifies the following three properties:\n\n\\(0 \\in \\mathscr{B}\\) (the empty set is an element of \\(\\mathscr{B}\\))\nIf \\(A \\in \\mathscr{B}\\) then \\(A^c \\in \\mathscr{B}\\) (\\(\\mathscr{B}\\) is closed under complementation)\nIf \\(A_1, A_2, \\ldots \\in \\mathscr{B}\\) then \\(\\bigcup_{i=1}^\\infty A_i \\in \\mathscr{B}\\) (\\(\\mathscr{B}\\) is closed under countable unions).\n\n\n\n\n\n\n\nDefinition 1.2.4 Given a sample space \\(S\\) and an associated sigma algebra \\(\\mathscr{B}\\) that satisfies\n\n\\(P(A) \\ge 0\\) for all \\(A \\in \\mathscr{B}\\)\n\\(P(S) = 1\\)\nIf \\(A_1,A_2,\\ldots \\in \\mathscr{B}\\) are pairwise disjoint, then \\(P(\\bigcup_{i=1}^\\infty A_i) = \\sum_{i=1}^\\infty P(A)\\)\n\n\n\n\n\n\n\nTheorem 1.2.6 Let \\(S = {s_1,\\ldots,s_n}\\) be a finite set. Let \\(\\mathscr{B}\\) be any sigma algebra of subsets of \\(S\\). Let \\(p_1,\\ldots,p_n\\) be nonnegative numbers that sum to 1. For any \\(A \\in \\mathscr{B}\\), define \\(P(A)\\) by \\[\nP(A) = \\sum_{\\{i:s_i \\in A\\}} p_i\n\\] (The sum over an empty set is defined to be \\(0\\).) Then \\(P\\) is a probability function on \\(\\mathscr{B}\\). This remains true if \\(S={s_1, s_2, \\ldots }\\) is a countable set.\n\n\n\nTheorem 1.2.8 If \\(P\\) is a probability function and \\(A\\) is any set in \\(\\mathscr{B}\\), then\n\n\\(P(0) = 0\\) where \\(0\\) is the empty set;\n\\(P(A) \\le 1\\);\n\\(P(A^c) = 1 - P(A)\\).\n\n\n\n\nTheorem 1.2.9 If \\(P\\) is a probability function and \\(A\\) and \\(B\\) are any sets in \\(\\mathscr{B}\\) then\n\n\\(P(B \\cap A^c) = P(B) - P(A \\cap B)\\);\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\);\nIF \\(A \\subset B\\), then \\(P(A) \\le P(B)\\)",
    "crumbs": [
      "Probability"
    ]
  },
  {
    "objectID": "prob.html#sets",
    "href": "prob.html#sets",
    "title": "Chap 01: Probability Theory",
    "section": "",
    "text": "Definition 1.1.2 Let A, B be events, subsets of S, then:\nUnion: The union of A and B, written \\(A \\cup B\\) is the set of elements that belong to either A or B or both: \\[ A \\cup B = \\{x: x \\in A \\text{ or } x \\in B\\} \\] Intersection: The intersection of A and B, written \\(A \\cap B\\) is the set of elements that belong to both A and B: \\[ A \\cap B = \\{x: x \\in A \\text{ and } x \\in B\\} \\] Complement: The complement of A, written as \\(A^c\\), is the set of all elements that are not in A: \\[ A^c = \\{x: x \\notin A \\} \\]\n\n\nTheorem 1.1.4 For any three events, A, B and C, defined on a sample space S,\n\\[\\begin{array}{l l}\na. Commutativity    & A \\cup B = B \\cup A,\\\\\n                        & A \\cap B = B \\cap A;\\\\\nb. Associativity    & A \\cup (B \\cup C) = (A \\cup B)\\cup C,\\\\\n                        & $A \\cap (B \\cap C) = (A \\cap B)\\cap C;\\\\\nc. Distributive Laws    & A \\cap (B \\cup C) = (A \\cap B)\\cup (A \\cap C),\\\\\n                        & $A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C);\\\\\nd. DeMorgan's Laws & (A \\cup B)^c = A^c \\cap B^c ,\\\\\n                   & (A \\cap B)^c = A^c \\cup B^c .\n\n\\end{array}\\]\n\n\n\n\nDefinition If \\(A_1, A_2, A_3, \\ldots\\) is a collection of sets, all defined on a sample space \\(S\\), then\n\\[\\begin{align*}\n\\bigcup_{i=1}^\\infty A_i &= \\{x \\in S: x \\in A_i  \\text{ for some }i\\},\\\\\n\\bigcap_{i=1}^\\infty A_i &= \\{x \\in S: x \\in A_i  \\text{ for all }i\\}.\\\\\n\\end{align*}\\]\n\n\n\nDefinition 1.1.5 Two events \\(A\\) and \\(B\\) are disjoint (or mutually exclusive) if \\(A \\cap B = 0\\). The events \\(A_1,A_2,\\ldots\\) are pairwise disjoint (or mutually exclusive) if \\(A_i \\cap A_j = 0 \\text{ for all } i \\ne j\\).\n\n\n\nDefinition 1.1.6 If \\(A_1,A_2,\\ldots\\) are pairwise disjoint and \\(\\bigcup_{i=0}^\\infty A_i = S\\), then the collection \\(A_1, A_2, \\dots\\) forms a partition of S.\n\n\n\n\n\n\nDefinition 1.2.1 A collection of subsets of S is called a sigma algebra (or Borel field ), denoted by \\(\\mathscr{B}\\), if it satifies the following three properties:\n\n\\(0 \\in \\mathscr{B}\\) (the empty set is an element of \\(\\mathscr{B}\\))\nIf \\(A \\in \\mathscr{B}\\) then \\(A^c \\in \\mathscr{B}\\) (\\(\\mathscr{B}\\) is closed under complementation)\nIf \\(A_1, A_2, \\ldots \\in \\mathscr{B}\\) then \\(\\bigcup_{i=1}^\\infty A_i \\in \\mathscr{B}\\) (\\(\\mathscr{B}\\) is closed under countable unions).\n\n\n\n\n\n\n\nDefinition 1.2.4 Given a sample space \\(S\\) and an associated sigma algebra \\(\\mathscr{B}\\) that satisfies\n\n\\(P(A) \\ge 0\\) for all \\(A \\in \\mathscr{B}\\)\n\\(P(S) = 1\\)\nIf \\(A_1,A_2,\\ldots \\in \\mathscr{B}\\) are pairwise disjoint, then \\(P(\\bigcup_{i=1}^\\infty A_i) = \\sum_{i=1}^\\infty P(A)\\)\n\n\n\n\n\n\n\nTheorem 1.2.6 Let \\(S = {s_1,\\ldots,s_n}\\) be a finite set. Let \\(\\mathscr{B}\\) be any sigma algebra of subsets of \\(S\\). Let \\(p_1,\\ldots,p_n\\) be nonnegative numbers that sum to 1. For any \\(A \\in \\mathscr{B}\\), define \\(P(A)\\) by \\[\nP(A) = \\sum_{\\{i:s_i \\in A\\}} p_i\n\\] (The sum over an empty set is defined to be \\(0\\).) Then \\(P\\) is a probability function on \\(\\mathscr{B}\\). This remains true if \\(S={s_1, s_2, \\ldots }\\) is a countable set.\n\n\n\nTheorem 1.2.8 If \\(P\\) is a probability function and \\(A\\) is any set in \\(\\mathscr{B}\\), then\n\n\\(P(0) = 0\\) where \\(0\\) is the empty set;\n\\(P(A) \\le 1\\);\n\\(P(A^c) = 1 - P(A)\\).\n\n\n\n\nTheorem 1.2.9 If \\(P\\) is a probability function and \\(A\\) and \\(B\\) are any sets in \\(\\mathscr{B}\\) then\n\n\\(P(B \\cap A^c) = P(B) - P(A \\cap B)\\);\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\);\nIF \\(A \\subset B\\), then \\(P(A) \\le P(B)\\)",
    "crumbs": [
      "Probability"
    ]
  },
  {
    "objectID": "prob.html#sigma-algebra",
    "href": "prob.html#sigma-algebra",
    "title": "Chap 01: Probability Theory",
    "section": "2 Sigma-Algebra",
    "text": "2 Sigma-Algebra",
    "crumbs": [
      "Probability"
    ]
  },
  {
    "objectID": "prob.html#section",
    "href": "prob.html#section",
    "title": "Chap 01: Probability Theory",
    "section": "2 ",
    "text": "2 \n\nTheorem 1.2.6 Let \\(S = {s_1,\\ldots,s_n}\\) be a finite set. Let \\(\\mathscr{B}\\) be any sigma algebra$",
    "crumbs": [
      "Probability"
    ]
  }
]